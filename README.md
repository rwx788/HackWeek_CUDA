# HackWeek_CUDA
Getting Started with CUDA for parallel computing.

## Motivation
GPUs are widely used for parallel computations and CUDA is platform which simplifies development of such applications for NVidia GPUs.

AWS has AMIs which have CUDA toolkit pre-installed and can be used on EC2 instances with NVidia GPUs, which will simplify deployment of such applications.

Some guides can be found here:

* [easy-introduction-cuda-c-and-c](https://devblogs.nvidia.com/easy-introduction-cuda-c-and-c/)
* [how-to-cuda-c-cpp](https://developer.nvidia.com/how-to-cuda-c-cpp)
* [even-easier-introduction-cuda](https://devblogs.nvidia.com/even-easier-introduction-cuda/)
* [cuda-c-best-practices-guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html)
* [unified-memory-cuda-beginners](https://devblogs.nvidia.com/unified-memory-cuda-beginners/)
* [beyond-gpu-memory-limits-unified-memory-pascal](https://devblogs.nvidia.com/beyond-gpu-memory-limits-unified-memory-pascal/)
* [CUDA programming](https://github.com/romain-jacotin/cuda)
* [CUDA C programming guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#abstract)
* [how-overlap-data-transfers-cuda-cc](https://devblogs.nvidia.com/how-overlap-data-transfers-cuda-cc/)
* [how-access-global-memory-efficiently-cuda-c-kernels](https://devblogs.nvidia.com/how-access-global-memory-efficiently-cuda-c-kernels/)
* [using-shared-memory-cuda-cc](https://devblogs.nvidia.com/using-shared-memory-cuda-cc/)

## Goals
1. Getting familiar with parallel computations using CUDA
2. Recapping how AWS works and configuring development environment in the cloud
3. Implementing existing parallel computing algorithm, profiling it and applying optimizations
